MMVCの導入
==================

インストール
---------------------------------------------------------------------------
https://github.com/isletennos/MMVC_Trainer をダウンロードして、展開、展開したディレクトリをgoogle drive上にアップロードしてください。


ずんだもんの声になる
---------------------------------------------------------------------------


自分の音声の録音と音声データの配置
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

1. 自分の声の音声データを録音します。

    | JVSコーパスやITAコーパス等を台本にし、100文程度読み上げます。
    | 音声の録音ツールは
    | Audacity
    | https://forest.watch.impress.co.jp/library/software/audacity/
    | OREMO
    | http://nwp8861.web.fc2.com/soft/oremo/
    | 等があります。
    | また、録音した音声は24000Hz 16bit 1chである必要があります。
    
    .. note::
       MMVC用にテキストを分割したITAコーパスです。ご利用ください。
       https://drive.google.com/file/d/14oXoQqLxRkP8NJK8qMYGee1_q2uEED1z/view?usp=sharing
        

2. dataset/textful/000_myvoice に音声データとテキストデータを配置します。

   | 最終的に下記のようなディレクトリ構成になります。
   
   ::

      dataset
      ├── textful
      │   ├── 000_myvoice
      │   │   ├── text
      │   │   │   ├── s_voice_001.txt
      │   │   │   ├── s_voice_002.txt
      │   │   │   ├── ...
      │   │   └── wav
      │   │        ├── s_voice_001.wav
      │   │        ├── s_voice_002.wav
      │   │        ├── ...
      │   │── 001_target
      │   │   ├── text
      │   │   └── wav
      │   │
      │   └── 1205_zundamon
      │       ├── text
      │       │   ├── t_voice_001.txt
      │       │   ├── t_voice_002.txt
      │       │   ├── ...
      │       └── wav
      │            ├── t_voice_001.wav
      │            ├── t_voice_002.wav
      │            ├── ... 
      │        
      └── textless


モデルの学習方法
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1. 下記リンクより、「G_180000.pth」「D_180000.pth」をダウンロード。 https://drive.google.com/drive/folders/1XGpW0loNr1KjMtXVVG3WRd47R_ne6_X2?usp=sharing
2. 「G_180000.pth」「D_180000.pth」をfine_modelに配置します。(良く忘れるポイントなので要注意！)
3. notebookディレクトリにある「Create_Configfile_zundamon.ipynb」をgoogle colab 上で実行、学習に必要なconfigファイルを作成します
4. configsに作成されたtrain_config_zundamon.jsonの
    * "eval_interval"
        modelを保存する間隔です。
    * "batch_size"
        colabで割り当てたGPUに合わせて調整してください。
    上記2項目を環境に応じて最適化してください。わからない方はそのままで大丈夫です。
5. notebookディレクトリにある「Train_MMVC.ipynb」をgoogle colab 上で実行してください。
    logs/にモデルが生成されます。

学習したモデルの性能検証
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1. notebookディレクトリにある「MMVC_Interface.ipynb」をgoogle colab 上で実行してください。

好きなキャラクターの声になる
---------------------------------------------------------------------------


自分の音声の録音と音声データの配置 及びターゲット音声データの配置
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

1. 自分の声の音声データとその音声データに対応するテキスト、変換したい声の音声データとその音声データに対応するテキストを用意します。

   | この時、用意する音声(自分の声の音声データ/変換したい声の音声データ共に)は24000Hz 16bit 1chを強く推奨しております。
   | 九州そらと四国めたんのMMVC用のデータは下記リンクからダウンロードください。
   | ダウンロード後、2節のように音声データとテキストデータを配置してください。
   | https://drive.google.com/drive/folders/1ClIUx_2Wv-uNnuW2LlfG7aTHrUaZ2Asx?usp=sharing


2. 下記のようなディレクトリ構成になるように音声データとテキストデータを配置します。textfulの直下には2ディレクトリになります。

   | 1)自分の声の音声データとその音声データに対応するテキスト、変換したい声の音声データとその音声データに対応するテキストを用意します。
   | この時、用意する音声(自分の声の音声データ/変換したい声の音声データ共に)は24000Hz 16bit 1chを強く推奨しております。
   | 2)下記のようなディレクトリ構成になるように音声データとテキストデータを配置します。textfulの直下には2ディレクトリになります。
   
   ::

      dataset
      ├── textful
      │   ├── 000_myvoice
      │   │   ├── text
      │   │   │   ├── s_voice_001.txt
      │   │   │   ├── s_voice_002.txt
      │   │   │   ├── ...
      │   │   └── wav
      │   │        ├── s_voice_001.wav
      │   │        ├── s_voice_002.wav
      │   │        ├── ...
      │   │── 001_target
      │   │   ├── text
      │   │   │   ├── t_voice_001.txt
      │   │   │   ├── t_voice_002.txt
      │   │   │   ├── ...
      │   │   └── wav
      │   │        ├── t_voice_001.wav
      │   │        ├── t_voice_002.wav
      │   │        ├── ... 
      │   └── 1205_zundamon
      │       ├── text
      │       │   ├── t_voice_001.txt
      │       │   ├── t_voice_002.txt
      │       │   ├── ...
      │       └── wav
      │            ├── t_voice_001.wav
      │            ├── t_voice_002.wav
      │            ├── ... 
      │        
      └── textless


学習したモデルの性能検証、評価
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1. notebookディレクトリにある「MMVC_Interface.ipynb」をgoogle colab 上で実行してください。

有志による解説
---------------------------------------------------------------------------
| 前準備編
| https://www.nicovideo.jp/watch/sm40415108
